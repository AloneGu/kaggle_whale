{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../py_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "from model_utils import get_mobilenet_model\n",
    "from utils import get_train_test_data_dict, DictImageDataGenerator, preprocess_func\n",
    "\n",
    "# define train params\n",
    "IMG_SIZE = 224\n",
    "LABEL_CNT = 5005\n",
    "ALL_DATA_JSON = '../data/train_data.json'\n",
    "BATCH_SIZE = 8\n",
    "print('load done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23996 images belonging to 5005 classes.\n",
      "Found 12248 images belonging to 5005 classes.\n",
      "1531\n",
      "(8, 224, 224, 3) (8, 5005)\n"
     ]
    }
   ],
   "source": [
    "# get generator\n",
    "train_d, val_d = get_train_test_data_dict(ALL_DATA_JSON, 0.1)\n",
    "train_ds = DictImageDataGenerator(rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  preprocessing_function=preprocess_func)\n",
    "train_gen = train_ds.flow_from_dict(train_d, target_size=(\n",
    "    IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "val_ds = DictImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "val_gen = val_ds.flow_from_dict(val_d, target_size=(\n",
    "    IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "val_steps = val_gen.samples//BATCH_SIZE\n",
    "print(val_steps)\n",
    "# test\n",
    "for x, y in train_gen:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:206: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5005)              1286285   \n",
      "=================================================================\n",
      "Total params: 4,777,549\n",
      "Trainable params: 4,755,661\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get baseline mobilenet model\n",
    "mob_model = get_mobilenet_model(IMG_SIZE, LABEL_CNT, dense_dim=256)\n",
    "mob_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile done\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "def get_callbacks(model_save_path, model=None):\n",
    "    if os.path.exists(model_save_path):\n",
    "        if model is not None:\n",
    "            model.load_weights(model_save_path)\n",
    "    model_dir = os.path.dirname(model_save_path)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    m_reduce = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='loss', factor=0.5, patience=3, verbose=1, min_lr=0.00000001)\n",
    "    m_check = keras.callbacks.ModelCheckpoint(\n",
    "        model_save_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    return [m_reduce, m_check]\n",
    "\n",
    "cb_list = get_callbacks('../data/checkpoints/mob_base.h5', mob_model)\n",
    "mob_model.compile(optimizer=adam_opt,\n",
    "                  loss='categorical_crossentropy', metrics=['acc'])\n",
    "print('compile done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 1944s 972ms/step - loss: 11.6472 - acc: 0.3596 - val_loss: 10.8742 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.87423, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1907s 954ms/step - loss: 10.9381 - acc: 0.3618 - val_loss: 9.2746 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.87423 to 9.27458, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1899s 949ms/step - loss: 11.1265 - acc: 0.3656 - val_loss: 10.9416 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 9.27458\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1906s 953ms/step - loss: 10.4271 - acc: 0.3623 - val_loss: 11.0415 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 9.27458\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1907s 953ms/step - loss: 10.0223 - acc: 0.3587 - val_loss: 10.7185 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 9.27458\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1917s 958ms/step - loss: 10.0197 - acc: 0.3664 - val_loss: 10.4863 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 9.27458\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1897s 949ms/step - loss: 10.3147 - acc: 0.3652 - val_loss: 10.5595 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 9.27458\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1900s 950ms/step - loss: 9.8151 - acc: 0.3599 - val_loss: 10.1737 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 9.27458\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1906s 953ms/step - loss: 9.5230 - acc: 0.3624 - val_loss: 11.2568 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 9.27458\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1894s 947ms/step - loss: 9.3077 - acc: 0.3598 - val_loss: 10.0849 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 9.27458\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 1896s 948ms/step - loss: 9.3982 - acc: 0.3636 - val_loss: 9.4287 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 9.27458\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 1891s 945ms/step - loss: 10.6315 - acc: 0.3641 - val_loss: 11.2260 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 9.27458\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 1887s 943ms/step - loss: 9.4529 - acc: 0.3656 - val_loss: 10.0189 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 9.27458\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 1897s 949ms/step - loss: 8.6051 - acc: 0.3569 - val_loss: 9.9696 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 9.27458\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 1900s 950ms/step - loss: 8.4341 - acc: 0.3649 - val_loss: 9.6403 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 9.27458\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 1886s 943ms/step - loss: 8.3107 - acc: 0.3602 - val_loss: 9.1953 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00016: val_loss improved from 9.27458 to 9.19531, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 1894s 947ms/step - loss: 8.7141 - acc: 0.3639 - val_loss: 9.4681 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 9.19531\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 1896s 948ms/step - loss: 8.5872 - acc: 0.3633 - val_loss: 9.7434 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 9.19531\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 1894s 947ms/step - loss: 8.3011 - acc: 0.3621 - val_loss: 9.8248 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 9.19531\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 1908s 954ms/step - loss: 8.1529 - acc: 0.3649 - val_loss: 9.1122 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00020: val_loss improved from 9.19531 to 9.11223, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 1917s 958ms/step - loss: 8.2327 - acc: 0.3604 - val_loss: 9.0367 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00021: val_loss improved from 9.11223 to 9.03668, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 1902s 951ms/step - loss: 8.3451 - acc: 0.3629 - val_loss: 9.8462 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 9.03668\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 1910s 955ms/step - loss: 8.2926 - acc: 0.3621 - val_loss: 8.6683 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00023: val_loss improved from 9.03668 to 8.66835, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 1902s 951ms/step - loss: 8.0247 - acc: 0.3624 - val_loss: 9.2588 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 8.66835\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 1913s 957ms/step - loss: 8.0795 - acc: 0.3624 - val_loss: 9.0166 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 8.66835\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 1894s 947ms/step - loss: 8.0114 - acc: 0.3625 - val_loss: 7.9423 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00026: val_loss improved from 8.66835 to 7.94230, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 1923s 962ms/step - loss: 8.1231 - acc: 0.3624 - val_loss: 8.6905 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 7.94230\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 1908s 954ms/step - loss: 8.0795 - acc: 0.3665 - val_loss: 8.8450 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 7.94230\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 1913s 957ms/step - loss: 8.0157 - acc: 0.3591 - val_loss: 9.2119 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 7.94230\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 1908s 954ms/step - loss: 8.2017 - acc: 0.3618 - val_loss: 7.9129 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00030: val_loss improved from 7.94230 to 7.91288, saving model to ../data/checkpoints/mob_base.h5\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 1910s 955ms/step - loss: 8.0724 - acc: 0.3626 - val_loss: 8.8260 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 7.91288\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 1917s 959ms/step - loss: 7.9900 - acc: 0.3660 - val_loss: 8.3502 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 7.91288\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 1929s 964ms/step - loss: 8.2040 - acc: 0.3589 - val_loss: 8.5203 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 7.91288\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 1938s 969ms/step - loss: 7.2536 - acc: 0.3623 - val_loss: 8.4118 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 7.91288\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 1920s 960ms/step - loss: 7.9618 - acc: 0.3629 - val_loss: 8.2589 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 7.91288\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 1920s 960ms/step - loss: 7.9370 - acc: 0.3622 - val_loss: 8.4996 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 7.91288\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 1929s 965ms/step - loss: 8.2110 - acc: 0.3626 - val_loss: 9.2394 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 7.91288\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 1906s 953ms/step - loss: 8.6233 - acc: 0.3610 - val_loss: 8.6157 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 7.91288\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 2054s 1s/step - loss: 9.1762 - acc: 0.3638 - val_loss: 8.6065 - val_acc: 0.0789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_loss did not improve from 7.91288\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 2061s 1s/step - loss: 9.1380 - acc: 0.3619 - val_loss: 8.6407 - val_acc: 0.0789\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 7.91288\n",
      "Epoch 41/100\n",
      " 576/2000 [=======>......................] - ETA: 22:02 - loss: 9.2693 - acc: 0.3557"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-098abc42c4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "mob_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=cb_list,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
