{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../py_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n",
      "7732\n",
      "1932\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "from model_utils import get_mobilenet_model, get_callbacks\n",
    "from utils import get_train_test_data_dict, DictImageDataGenerator, preprocess_func\n",
    "from utils import get_if_new_whale_dict, split_train_test_dict\n",
    "\n",
    "# define train params\n",
    "IMG_SIZE = 224\n",
    "LABEL_CNT = 2\n",
    "ALL_DATA_JSON = '../data/train_data.json'\n",
    "BATCH_SIZE = 8\n",
    "ALL_DATA_DICT = json.loads(open(ALL_DATA_JSON).read())\n",
    "print('load done')\n",
    "\n",
    "if_whale_d = get_if_new_whale_dict(ALL_DATA_DICT)\n",
    "train_d, val_d = split_train_test_dict(if_whale_d)\n",
    "print(len(train_d['new_whale']))\n",
    "print(len(val_d['new_whale']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20290 images belonging to 2 classes.\n",
      "Using bbox for image\n",
      "Found 5071 images belonging to 2 classes.\n",
      "Using bbox for image\n",
      "633\n",
      "(8, 224, 224, 3) (8, 2)\n",
      "{'new_whale': 0, 'not_new_whale': 1}\n"
     ]
    }
   ],
   "source": [
    "train_ds = DictImageDataGenerator(rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  preprocessing_function=preprocess_func)\n",
    "train_gen = train_ds.flow_from_dict(train_d, target_size=(\n",
    "    IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "val_ds = DictImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "val_gen = val_ds.flow_from_dict(val_d, target_size=(\n",
    "    IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "val_steps = val_gen.samples//BATCH_SIZE\n",
    "print(val_steps)\n",
    "# test\n",
    "for x, y in train_gen:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:206: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,294,594\n",
      "Trainable params: 3,272,706\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mob_model = get_mobilenet_model(IMG_SIZE, LABEL_CNT, dense_dim=64)\n",
    "mob_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pre weights\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "cb_list = get_callbacks('../data/checkpoints/detect_if_new_whale_bbox.h5', mob_model)\n",
    "adam_opt = keras.optimizers.Adam(lr=0.001)\n",
    "mob_model.compile(optimizer=adam_opt,\n",
    "                  loss='categorical_crossentropy', metrics=['acc'])\n",
    "print('compile done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 1900s 950ms/step - loss: 0.4547 - acc: 0.7922 - val_loss: 0.5039 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.50386, saving model to ../data/checkpoints/detect_if_new_whale_bbox.h5\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1931s 966ms/step - loss: 0.4479 - acc: 0.7944 - val_loss: 0.4627 - val_acc: 0.7979\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.50386 to 0.46272, saving model to ../data/checkpoints/detect_if_new_whale_bbox.h5\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1799s 900ms/step - loss: 0.4484 - acc: 0.7927 - val_loss: 0.4805 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.46272\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1802s 901ms/step - loss: 0.4474 - acc: 0.7952 - val_loss: 0.5355 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46272\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1793s 897ms/step - loss: 0.4419 - acc: 0.7987 - val_loss: 0.4745 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.46272\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1810s 905ms/step - loss: 0.4410 - acc: 0.8019 - val_loss: 0.4746 - val_acc: 0.7892\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.46272\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1793s 897ms/step - loss: 0.4355 - acc: 0.7989 - val_loss: 0.5349 - val_acc: 0.7811\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.46272\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1789s 895ms/step - loss: 0.4344 - acc: 0.8042 - val_loss: 0.4898 - val_acc: 0.7837\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.46272\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1801s 901ms/step - loss: 0.4356 - acc: 0.8029 - val_loss: 0.5630 - val_acc: 0.7596\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.46272\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1777s 889ms/step - loss: 0.4297 - acc: 0.8062 - val_loss: 0.4808 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.46272\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 1773s 886ms/step - loss: 0.4286 - acc: 0.8066 - val_loss: 0.4886 - val_acc: 0.7849\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.46272\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 1779s 889ms/step - loss: 0.4279 - acc: 0.8071 - val_loss: 0.5532 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.46272\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 1791s 896ms/step - loss: 0.4228 - acc: 0.8101 - val_loss: 0.5297 - val_acc: 0.7701\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.46272\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 1768s 884ms/step - loss: 0.4309 - acc: 0.8022 - val_loss: 0.5608 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.46272\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 1800s 900ms/step - loss: 0.4189 - acc: 0.8146 - val_loss: 0.5254 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.46272\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 1781s 890ms/step - loss: 0.4187 - acc: 0.8103 - val_loss: 0.5687 - val_acc: 0.7718\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.46272\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 1776s 888ms/step - loss: 0.4156 - acc: 0.8130 - val_loss: 0.5039 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.46272\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 1787s 894ms/step - loss: 0.4162 - acc: 0.8157 - val_loss: 0.5563 - val_acc: 0.7647\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.46272\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 1791s 895ms/step - loss: 0.4111 - acc: 0.8144 - val_loss: 0.5032 - val_acc: 0.7776\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.46272\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 1774s 887ms/step - loss: 0.4092 - acc: 0.8182 - val_loss: 0.5104 - val_acc: 0.7588\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.46272\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 1782s 891ms/step - loss: 0.4005 - acc: 0.8192 - val_loss: 0.5358 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.46272\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 1770s 885ms/step - loss: 0.4072 - acc: 0.8205 - val_loss: 0.5297 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.46272\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 1776s 888ms/step - loss: 0.3999 - acc: 0.8233 - val_loss: 0.5111 - val_acc: 0.7758\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.46272\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 1765s 883ms/step - loss: 0.3977 - acc: 0.8239 - val_loss: 0.4983 - val_acc: 0.7693\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.46272\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 1781s 890ms/step - loss: 0.3966 - acc: 0.8254 - val_loss: 0.5172 - val_acc: 0.7770\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.46272\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 1768s 884ms/step - loss: 0.3941 - acc: 0.8289 - val_loss: 0.5013 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.46272\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 1765s 883ms/step - loss: 0.3924 - acc: 0.8244 - val_loss: 0.5741 - val_acc: 0.7726\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.46272\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 1776s 888ms/step - loss: 0.3902 - acc: 0.8267 - val_loss: 0.5501 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.46272\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 1804s 902ms/step - loss: 0.3803 - acc: 0.8316 - val_loss: 0.5629 - val_acc: 0.7555\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.46272\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 1814s 907ms/step - loss: 0.3834 - acc: 0.8321 - val_loss: 0.5816 - val_acc: 0.7618\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.46272\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 1791s 896ms/step - loss: 0.3793 - acc: 0.8315 - val_loss: 0.5701 - val_acc: 0.7722\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.46272\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 1829s 914ms/step - loss: 0.3773 - acc: 0.8321 - val_loss: 0.5243 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.46272\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 1794s 897ms/step - loss: 0.3785 - acc: 0.8310 - val_loss: 0.5245 - val_acc: 0.7795\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.46272\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 1809s 905ms/step - loss: 0.3742 - acc: 0.8355 - val_loss: 0.5130 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.46272\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 1804s 902ms/step - loss: 0.3652 - acc: 0.8417 - val_loss: 0.5858 - val_acc: 0.7549\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.46272\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 1781s 891ms/step - loss: 0.3687 - acc: 0.8376 - val_loss: 0.5360 - val_acc: 0.7711\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.46272\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 1769s 885ms/step - loss: 0.3690 - acc: 0.8376 - val_loss: 0.5260 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.46272\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 1788s 894ms/step - loss: 0.3642 - acc: 0.8435 - val_loss: 0.5442 - val_acc: 0.7563\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.46272\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 1787s 893ms/step - loss: 0.3577 - acc: 0.8419 - val_loss: 0.6229 - val_acc: 0.7632\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.46272\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 1782s 891ms/step - loss: 0.3621 - acc: 0.8384 - val_loss: 0.5512 - val_acc: 0.7754\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.46272\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 1777s 888ms/step - loss: 0.3563 - acc: 0.8424 - val_loss: 0.5695 - val_acc: 0.7742\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.46272\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 1791s 895ms/step - loss: 0.3591 - acc: 0.8418 - val_loss: 0.6247 - val_acc: 0.7620\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.46272\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1781s 890ms/step - loss: 0.3529 - acc: 0.8462 - val_loss: 0.5801 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.46272\n",
      "Epoch 44/100\n",
      " 439/2000 [=====>........................] - ETA: 21:57 - loss: 0.3384 - acc: 0.8548"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bacf30f4ba86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# no box log\n",
    "# Epoch 00024: val_loss improved from 0.48239 to 0.48106, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
    "# loss: 0.4322 - acc: 0.8033 - val_loss: 0.5065 - val_acc: 0.7742\n",
    "\n",
    "# Epoch 00002: val_loss improved from 0.50386 to 0.46272, saving model to ../data/checkpoints/detect_if_new_whale_bbox.h5\n",
    "# loss: 0.4479 - acc: 0.7944 - val_loss: 0.4627 - val_acc: 0.7979\n",
    "\n",
    "# train\n",
    "mob_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=cb_list,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
