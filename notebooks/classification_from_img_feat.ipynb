{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_ebb99e5 ../data/train/0ba0e60f3.jpg (256,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "IMG_FEAT_PATH = '../data/simaese_img_feats/simaese_mob_299_sim_best_train_loss.pkl'\n",
    "\n",
    "fin = open(IMG_FEAT_PATH, 'rb')\n",
    "train_feats = pickle.load(fin)\n",
    "fin.close()\n",
    "print(train_feats[0][0], train_feats[0][1], train_feats[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left labels 1646\n",
      "(11054, 256) (11054,)\n"
     ]
    }
   ],
   "source": [
    "# only keep label cnt >= 2\n",
    "x_data, y_data = [], []\n",
    "train_cnt = {}\n",
    "for label, _, _ in train_feats:\n",
    "    if label not in train_cnt:\n",
    "        train_cnt[label] = 0\n",
    "    train_cnt[label] += 1\n",
    "\n",
    "filter_labels = set()\n",
    "for label in train_cnt:\n",
    "    if train_cnt[label] >= 3:\n",
    "        filter_labels.add(label)\n",
    "print('left labels', len(filter_labels))\n",
    "\n",
    "for label, _, feat in train_feats:\n",
    "    if label in filter_labels:\n",
    "        x_data.append(feat)\n",
    "        y_data.append(label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_l_data = le.fit_transform(y_data)\n",
    "x_data = np.array(x_data)\n",
    "print(x_data.shape, y_l_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w_0027efa' 'w_003bae6' 'w_007fefa' ... 'w_fec5547' 'w_ff2157c'\n",
      " 'w_ffa542b']\n",
      "1646\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)\n",
    "print(len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n"
     ]
    }
   ],
   "source": [
    "# cv check\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_l_data, test_size=0.33, random_state=42)\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "lr_model.fit(x_data, y_l_data)\n",
    "print('fit done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data score 0.20915505699294373\n",
      "test data score 0.21134868421052633\n",
      "[8.09095308e-04 4.02344437e-05 5.46170862e-03 ... 3.85406255e-06\n",
      " 5.62370183e-07 4.86558397e-06] 1.0\n",
      "check topk for distribution\n",
      "0.3519736842105263\n",
      "0.39473684210526316\n",
      "0.4322916666666667\n"
     ]
    }
   ],
   "source": [
    "print('all data score', lr_model.score(x_data, y_l_data))\n",
    "print('test data score', lr_model.score(X_test, y_test))\n",
    "all_pred = lr_model.predict_proba(x_data)\n",
    "test_pred = lr_model.predict_proba(X_test)\n",
    "print(test_pred[0], sum(test_pred[0]))\n",
    "\n",
    "\n",
    "def check_topk_acc(y_true, y_pred, k=3):\n",
    "    correct = 0\n",
    "    for i, tmp_pred in enumerate(y_pred):\n",
    "        topk = tmp_pred.argsort()[-k:]\n",
    "        # print(topk,y_true[i])\n",
    "        if y_true[i] in topk:\n",
    "            correct += 1\n",
    "    print(correct*1.0/len(y_true))\n",
    "\n",
    "\n",
    "print('check topk for distribution')\n",
    "check_topk_acc(y_test, test_pred, 3)\n",
    "check_topk_acc(y_test, test_pred, 4)\n",
    "check_topk_acc(y_test, test_pred, 5) \n",
    "\n",
    "# label_cnt >=4 \n",
    "# all data score 0.24545454545454545\n",
    "# test data score 0.24692158133506156\n",
    "# [3.61351534e-06 1.42040442e-06 1.19540025e-04 ... 4.44171080e-06\n",
    "#  6.37715558e-08 3.44947124e-08] 1.0000000000000007\n",
    "# check topk for distribution\n",
    "# 0.40926766040181467\n",
    "# 0.4594944912508101\n",
    "# 0.49773169151004537\n",
    "\n",
    "# label_cnt >= 3\n",
    "# all data score 0.20915505699294373\n",
    "# test data score 0.21134868421052633\n",
    "# [8.09095308e-04 4.02344437e-05 5.46170862e-03 ... 3.85406255e-06\n",
    "#  5.62370183e-07 4.86558397e-06] 1.0\n",
    "# check topk for distribution\n",
    "# 0.3519736842105263\n",
    "# 0.39473684210526316\n",
    "# 0.4322916666666667\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save done\n"
     ]
    }
   ],
   "source": [
    "with open('../data/checkpoints/lr_top3_model.pkl', 'wb') as fout:\n",
    "    pickle.dump(lr_model, fout)\n",
    "print('save done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
