{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../py_scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n",
      "7732\n",
      "1932\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "from model_utils import get_mobilenet_model, get_callbacks\n",
    "from utils import get_train_test_data_dict, DictImageDataGenerator, preprocess_func\n",
    "from utils import get_if_new_whale_dict, split_train_test_dict\n",
    "\n",
    "# define train params\n",
    "IMG_SIZE = 224\n",
    "LABEL_CNT = 2\n",
    "ALL_DATA_JSON = '../data/train_data.json'\n",
    "BATCH_SIZE = 8\n",
    "ALL_DATA_DICT = json.loads(open(ALL_DATA_JSON).read())\n",
    "print('load done')\n",
    "\n",
    "if_whale_d = get_if_new_whale_dict(ALL_DATA_DICT)\n",
    "train_d, val_d = split_train_test_dict(if_whale_d)\n",
    "print(len(train_d['new_whale']))\n",
    "print(len(val_d['new_whale']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20290 images belonging to 2 classes.\n",
      "Found 5071 images belonging to 2 classes.\n",
      "633\n",
      "(8, 224, 224, 3) (8, 2)\n",
      "{'new_whale': 0, 'not_new_whale': 1}\n"
     ]
    }
   ],
   "source": [
    "train_ds = DictImageDataGenerator(rotation_range=20,\n",
    "                                  width_shift_range=0.2,\n",
    "                                  height_shift_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  preprocessing_function=preprocess_func)\n",
    "train_gen = train_ds.flow_from_dict(train_d, target_size=(\n",
    "    IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "val_ds = DictImageDataGenerator(preprocessing_function=preprocess_func)\n",
    "val_gen = val_ds.flow_from_dict(val_d, target_size=(\n",
    "    IMG_SIZE, IMG_SIZE), batch_size=BATCH_SIZE)\n",
    "val_steps = val_gen.samples//BATCH_SIZE\n",
    "print(val_steps)\n",
    "# test\n",
    "for x, y in train_gen:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "print(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras_applications/mobilenet.py:206: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 3,294,594\n",
      "Trainable params: 3,272,706\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mob_model = get_mobilenet_model(IMG_SIZE, LABEL_CNT, dense_dim=64)\n",
    "mob_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pre weights\n",
      "compile done\n"
     ]
    }
   ],
   "source": [
    "cb_list = get_callbacks('../data/checkpoints/detect_if_new_whale.h5', mob_model)\n",
    "adam_opt = keras.optimizers.Adam(lr=0.001)\n",
    "mob_model.compile(optimizer=adam_opt,\n",
    "                  loss='categorical_crossentropy', metrics=['acc'])\n",
    "print('compile done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 1849s 924ms/step - loss: 4.3577 - acc: 0.7237 - val_loss: 4.0798 - val_acc: 0.7409\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.07979, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1772s 886ms/step - loss: 4.4680 - acc: 0.7149 - val_loss: 4.3990 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.07979\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1783s 892ms/step - loss: 3.9597 - acc: 0.7217 - val_loss: 1.9783 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.07979 to 1.97825, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1782s 891ms/step - loss: 1.2917 - acc: 0.7000 - val_loss: 1.1692 - val_acc: 0.7363\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.97825 to 1.16916, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1792s 896ms/step - loss: 0.8596 - acc: 0.7047 - val_loss: 0.6027 - val_acc: 0.7446\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.16916 to 0.60269, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1772s 886ms/step - loss: 0.5634 - acc: 0.7192 - val_loss: 0.5177 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.60269 to 0.51768, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1781s 891ms/step - loss: 0.5265 - acc: 0.7469 - val_loss: 0.5132 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.51768 to 0.51319, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1771s 885ms/step - loss: 0.5159 - acc: 0.7561 - val_loss: 0.4939 - val_acc: 0.7758\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.51319 to 0.49388, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1773s 886ms/step - loss: 0.5005 - acc: 0.7661 - val_loss: 0.5023 - val_acc: 0.7707\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.49388\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1783s 892ms/step - loss: 0.4961 - acc: 0.7684 - val_loss: 0.4900 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.49388 to 0.48996, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 1780s 890ms/step - loss: 0.4836 - acc: 0.7782 - val_loss: 0.4976 - val_acc: 0.7712\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.48996\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 1771s 885ms/step - loss: 0.4814 - acc: 0.7772 - val_loss: 0.5287 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48996\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 1770s 885ms/step - loss: 0.4854 - acc: 0.7734 - val_loss: 0.5013 - val_acc: 0.7716\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48996\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 1772s 886ms/step - loss: 0.4800 - acc: 0.7795 - val_loss: 0.4927 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48996\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 1786s 893ms/step - loss: 0.4723 - acc: 0.7824 - val_loss: 0.5225 - val_acc: 0.7582\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48996\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 1788s 894ms/step - loss: 0.4733 - acc: 0.7813 - val_loss: 0.4862 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48996 to 0.48618, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 1767s 883ms/step - loss: 0.4674 - acc: 0.7866 - val_loss: 0.4824 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.48618 to 0.48239, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 1778s 889ms/step - loss: 0.4590 - acc: 0.7901 - val_loss: 0.4934 - val_acc: 0.7770\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.48239\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 1769s 885ms/step - loss: 0.4716 - acc: 0.7846 - val_loss: 0.5217 - val_acc: 0.7742\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.48239\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 1778s 889ms/step - loss: 0.4595 - acc: 0.7903 - val_loss: 0.5100 - val_acc: 0.7661\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.48239\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 1775s 887ms/step - loss: 0.4491 - acc: 0.7957 - val_loss: 0.4988 - val_acc: 0.7724\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.48239\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 1766s 883ms/step - loss: 0.4501 - acc: 0.7974 - val_loss: 0.4969 - val_acc: 0.7714\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.48239\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 1761s 880ms/step - loss: 0.4561 - acc: 0.7921 - val_loss: 0.5269 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.48239\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 1769s 884ms/step - loss: 0.4537 - acc: 0.7929 - val_loss: 0.4811 - val_acc: 0.7799\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.48239 to 0.48106, saving model to ../data/checkpoints/detect_if_new_whale.h5\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 1763s 881ms/step - loss: 0.4322 - acc: 0.8033 - val_loss: 0.5065 - val_acc: 0.7742\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.48106\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 1764s 882ms/step - loss: 0.4303 - acc: 0.8049 - val_loss: 0.4929 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.48106\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 1768s 884ms/step - loss: 0.4246 - acc: 0.8108 - val_loss: 0.5138 - val_acc: 0.7669\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.48106\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 1807s 903ms/step - loss: 0.4128 - acc: 0.8132 - val_loss: 0.5077 - val_acc: 0.7772\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.48106\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 1801s 901ms/step - loss: 0.4135 - acc: 0.8183 - val_loss: 0.5016 - val_acc: 0.7797\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.48106\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 1763s 881ms/step - loss: 0.4158 - acc: 0.8154 - val_loss: 0.5175 - val_acc: 0.7744\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.48106\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 1775s 888ms/step - loss: 0.4135 - acc: 0.8137 - val_loss: 0.4881 - val_acc: 0.7762\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.48106\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 1788s 894ms/step - loss: 0.3991 - acc: 0.8215 - val_loss: 0.5162 - val_acc: 0.7791\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.48106\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 1817s 908ms/step - loss: 0.3924 - acc: 0.8257 - val_loss: 0.5106 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.48106\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 1827s 913ms/step - loss: 0.3878 - acc: 0.8303 - val_loss: 0.5164 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.48106\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 1810s 905ms/step - loss: 0.3860 - acc: 0.8293 - val_loss: 0.5211 - val_acc: 0.7815\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.48106\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 1805s 902ms/step - loss: 0.3861 - acc: 0.8313 - val_loss: 0.5479 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.48106\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 1825s 913ms/step - loss: 0.3813 - acc: 0.8336 - val_loss: 0.5269 - val_acc: 0.7770\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.48106\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 1817s 908ms/step - loss: 0.3823 - acc: 0.8329 - val_loss: 0.5065 - val_acc: 0.7823\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.48106\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1816s 908ms/step - loss: 0.3771 - acc: 0.8341 - val_loss: 0.5432 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.48106\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 1813s 907ms/step - loss: 0.3819 - acc: 0.8324 - val_loss: 0.5264 - val_acc: 0.7801\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.48106\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 1819s 909ms/step - loss: 0.3727 - acc: 0.8388 - val_loss: 0.5277 - val_acc: 0.7789\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.48106\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 1810s 905ms/step - loss: 0.3773 - acc: 0.8325 - val_loss: 0.5178 - val_acc: 0.7750\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.48106\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 1857s 929ms/step - loss: 0.3679 - acc: 0.8406 - val_loss: 0.5620 - val_acc: 0.7764\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.48106\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 1797s 899ms/step - loss: 0.3668 - acc: 0.8395 - val_loss: 0.5472 - val_acc: 0.7774\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.48106\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 1779s 889ms/step - loss: 0.3695 - acc: 0.8366 - val_loss: 0.5323 - val_acc: 0.7766\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.48106\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 1767s 884ms/step - loss: 0.3703 - acc: 0.8397 - val_loss: 0.5784 - val_acc: 0.7766\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.48106\n",
      "Epoch 47/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.3662 - acc: 0.8399"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-098abc42c4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    228\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                             workers=0)\n\u001b[0m\u001b[1;32m    231\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                         \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1469\u001b[0;31m             verbose=verbose)\n\u001b[0m\u001b[1;32m   1470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m    341\u001b[0m                                  \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                                  str(generator_output))\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m             \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mouts_per_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "mob_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=cb_list,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
