{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_b938e96 ../data/train/054bb95c0.jpg (256,)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "IMG_FEAT_PATH = '../data/simaese_img_feats/simaese_mob_299_sim_hbp_best_train_loss.pkl'\n",
    "\n",
    "fin = open(IMG_FEAT_PATH, 'rb')\n",
    "train_feats = pickle.load(fin)\n",
    "fin.close()\n",
    "print(train_feats[0][0], train_feats[0][1], train_feats[0][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left labels 1078\n",
      "(9350, 256) (9350,)\n"
     ]
    }
   ],
   "source": [
    "# only keep label cnt >= 2\n",
    "x_data, y_data = [], []\n",
    "train_cnt = {}\n",
    "for label, _, _ in train_feats:\n",
    "    if label not in train_cnt:\n",
    "        train_cnt[label] = 0\n",
    "    train_cnt[label] += 1\n",
    "\n",
    "filter_labels = set()\n",
    "for label in train_cnt:\n",
    "    if train_cnt[label] >=4 :\n",
    "        filter_labels.add(label)\n",
    "print('left labels', len(filter_labels))\n",
    "\n",
    "for label, _, feat in train_feats:\n",
    "    if label in filter_labels:\n",
    "        x_data.append(feat)\n",
    "        y_data.append(label)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_l_data = le.fit_transform(y_data)\n",
    "x_data = np.array(x_data)\n",
    "print(x_data.shape, y_l_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w_0027efa' 'w_003bae6' 'w_007fefa' ... 'w_fec331a' 'w_fec5547'\n",
      " 'w_ff2157c']\n",
      "1078\n"
     ]
    }
   ],
   "source": [
    "print(le.classes_)\n",
    "print(len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit done\n"
     ]
    }
   ],
   "source": [
    "# cv check\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x_data, y_l_data, test_size=0.33, random_state=42)\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "lr_model.fit(x_data, y_l_data)\n",
    "print('fit done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data score 0.2474866310160428\n",
      "test data score 0.2524303305249514\n",
      "[4.35346186e-03 6.53737412e-03 6.97298824e-06 ... 3.42658140e-03\n",
      " 2.60473778e-03 2.40953454e-04] 0.9999999999999992\n",
      "check topk for distribution\n",
      "0.41088788075178223\n",
      "0.46208684381075826\n",
      "0.5100453661697991\n"
     ]
    }
   ],
   "source": [
    "print('all data score', lr_model.score(x_data, y_l_data))\n",
    "print('test data score', lr_model.score(X_test, y_test))\n",
    "all_pred = lr_model.predict_proba(x_data)\n",
    "test_pred = lr_model.predict_proba(X_test)\n",
    "print(test_pred[0], sum(test_pred[0]))\n",
    "\n",
    "\n",
    "def check_topk_acc(y_true, y_pred, k=3):\n",
    "    correct = 0\n",
    "    for i, tmp_pred in enumerate(y_pred):\n",
    "        topk = tmp_pred.argsort()[-k:]\n",
    "        # print(topk,y_true[i])\n",
    "        if y_true[i] in topk:\n",
    "            correct += 1\n",
    "    print(correct*1.0/len(y_true))\n",
    "\n",
    "\n",
    "print('check topk for distribution')\n",
    "check_topk_acc(y_test, test_pred, 3)\n",
    "check_topk_acc(y_test, test_pred, 4)\n",
    "check_topk_acc(y_test, test_pred, 5) \n",
    "\n",
    "# label_cnt >=4 \n",
    "# all data score 0.2474866310160428\n",
    "# test data score 0.2524303305249514\n",
    "# [4.35346186e-03 6.53737412e-03 6.97298824e-06 ... 3.42658140e-03\n",
    "#  2.60473778e-03 2.40953454e-04] 0.9999999999999992\n",
    "# check topk for distribution\n",
    "# 0.41088788075178223\n",
    "# 0.46208684381075826\n",
    "# 0.5100453661697991\n",
    "\n",
    "# label_cnt >= 3\n",
    "# all data score 0.21024063687352995\n",
    "# test data score 0.21710526315789475\n",
    "# [5.15169970e-06 1.66555342e-05 1.66082321e-06 ... 1.15979089e-06\n",
    "#  8.44756817e-04 3.39109691e-03] 1.0000000000000009\n",
    "# check topk for distribution\n",
    "# 0.3706140350877193\n",
    "# 0.4161184210526316\n",
    "# 0.45586622807017546\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save done\n"
     ]
    }
   ],
   "source": [
    "with open('../data/checkpoints/lr_top3_model.pkl', 'wb') as fout:\n",
    "    pickle.dump(lr_model, fout)\n",
    "print('save done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
